# Speeding up Second Life with object impostors

Animats Resident
August, 2018

## Introduction
Second Life is a virtual world with content created independently by thousands of people.
Second Life viewers must deal with that content and present it to the user efficiently. 
Highly detailed content can, and often does, choke the viewer, which then takes too long
to render each frame. This makes Second Life look sluggish in comparison to video games
and drives away users expecting a better experience.

This note lays out an approach to fixing this problem.

## Impostors
Impostors are a standard concept in computer graphics. The approach here uses simple
billboard impostors - flat rectangles which display a flat image. The billboard is
rotated to face the user's "camera", and depending on the angle to which it is rotated,
the image showm is changed. The images shown are simply stills of an object taken from
different angles.

(Example goes here.)

Second Life currently uses impostors for avatars. These are generated by the
viewer at low frame rate, about 4 frames per second. The same impostor image is
displayed for several viewer frames. More distant avatars are rendered as 
impostors to keep the display frame rate up. A few avatars, the nearest ones,
are rendered fully. This compromise makes it possible to have 10 to 40 avatars
in the same area without the viewer frame rate dropping to single digit frame rates.

There is no comparable system for objects.  This note is about creating one.

## Use cases
For design purposes, a few use cases are helpful. Most Second Life users have experienced these.
Most of these cause severely reduced frame rate today.

1. (CLUB) A crowded club, with about 30 avatars in motion. Background detail is not too important.

2. (SHOPPING) A shopping area with a large number of highly detailed items. Users want to look around 
and find items at a distance, then approach them and look at the details.

3. (DRIVING) Moderately fast driving, 50-100 km/hr. Users want to see where they are going, and 
sightsee their surroudings at a distance, but not examine them in detail.

## Making and using object impostors

### First demo
As a demo, to test impostor visual quality, a demo has been created. A simple 2-triangle billboard impostor
object turns to face the nearest avatar, and the appropriate texture is selected for display.
This is controlled by a Linden Scripting Language script, and works for only the nearest avatar.
This lets us see in world what impostors would look like, and gives a sense of how close an avatar can get
before the flatness of the impostor image becomes obvious.

Initial tests indicate that quite simple impostors of furniture-sized opjects look acceptable beyond 20-25 meters.
With the default Firestorm level of detail settings, objects have dropped to "low" level of detail at that point,
and the impostor usually looks better than the standard low level of detail model. An in-world demo of this is
being set up, and visiting that demo area is the way to see how this works.

The current impostor images are 128x64 pixels for each view, or 128x512 for the entire impostor. 

(SLURL goes here.)

To make impostor images, a picture-taking fixture is used. This rotates an object on a turntable in front of
a green screen, allowing the operator to take the set of pictures needed to make an impostor. A program in
Python clips the frame from each image, removes the green screen, resizes the image, and creates a single
texture ready for Second Life upload. 

The demo is a proof of concept. It lets people see what this would look like if implemented in the viewer.

### Sketch of a design for an in-viewer implementation
All this can probably be implemented in a basic form entirely within a viewer. The viewer needs to know
when the lowest level of detail of an object represents an impostor. 

#### Displaying an impostor
If possible, impostor display should be done by a vertex shader, with the graphics processor doing most of the work.

(MORE TO COME. NEED ADVICE FROM A SHADER EXPERT.)

#### Creating an impostor
Impostors would be created in advance, during mesh upload.  The object would be uploaded with its textures, a
feature currently present but not always used. The user would select "Impostor" for a level of detail below
the highest, and the uploader would render the object internally, taking the necessary images and combining
them into one, just like our test fixture does now. Since OpenGL can render an image with an alpha channel, there is
no need for a green screen to clip the image from the background. OpenGL can render an orthographic image,
as if taken from infinite distance, which is what's needed for an impostor. There's also the possibiilty of
generating normal, specular, and depth maps at this time, but those are future enhancements. 

This approach implies some restrictions. Mesh geometry and textures must be uploaded at the same time, so the impostor
generator gets to use both. Objects with impostors cannot be changed much once uploaded. Color changes and removal
or addition of links will not be reflected in the impostor. So this is for no-modify objects without color change
menus. 

For initial test purposes, impostors could be created entirely in Blender and uploaded as COLLADA files.
This is labor-intensive but useful for debugging.

#### Storing an impostor
For test purposes, an impostor would look like a lowest-level of detail model consisting of a flat image on one face
composed of two triangles centered at the object origin.
A standard viewer would display it as a flat image showing the object from one point of view.
A modified viewer would recognize this special case, perhaps by some name convention, 
and apply the special impostor shader, which would reposition the object vertices and UV coordinates to get the impostor effect.
So this would not look unacceptable in existing viewers, especially in comparision to the lowest level of detail models currently constructed
by the decimator in the uploader.

The document for the uploader indicates that it is possible to upload multiple textures for a single mesh model.
While each level of detail uses the same UV map, there's no requirement that each mesh have triangles for the entire UV map. So it should be possible to have a separate texture
for the impostor. (TEST THIS.)

#### Using an impostor
Once we have impostors working, they can be used more freely than low-LOD models. Objects with an impostor available can be dropped to impostor level of detail at distances as short as 20 meters.
Level of detail policy can be adjusted accordingly. A roughly uniform texture pixel to screen pixel ratio for everything on screen is a reasonable approach. 

#### Summary
It looks like this can be tried without breaking existing content, producing bad images in existing viewers, or making changes to the asset storage system. So it's not a breaking change.

## Further directions
#### Background generation of impostors
While beyond the scope of this note, the potential exists to generate impostors for existing objects as a background task running on SL-operated servers. That would speed up the display of old content. Changing an object would invalidate the impostor, which would have to be re-generated, much like the way pathfinding mesh is re-generated.

#### Large impostors
With background generation, there is the potential to generate large impostors, for entire parcels or even entire sims. Distant parcels could be replaced by impostors, and distant sims replaced by a ground mesh with a low-resolution texture. Google Earth does something similar. The user would see the Second Life world out to the horizon, no longer limited by draw distance. 

## Conclusion
There's considerable scope for speeding up Second Life in this way. It doesn't have to be slow just because it has complex user-generated content. The same techniques that make today's massively multiplayer online games look good while running fast can be retrofitted to Second Life. 

